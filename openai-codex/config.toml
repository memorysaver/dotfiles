## Codex CLI configuration
# Customize Codex CLI behavior via this config file.
# See https://github.com/openai/codex/blob/main/codex-rs/config.md for options.

# The default model (override as needed):
# model = "gpt-4.1"
model_provider = "openai"
model = "gpt-5-codex"
sandbox_mode = "workspace-write"

[model_providers.groq]
name = "groq"
base_url = "https://api.groq.com/openai/v1"
env_key = "GROQ_API_KEY"
approval_policy = "never"

[model_providers.openrouter]
name = "openrouter"
base_url="https://openrouter.ai/api/v1"
env_key = "OPENROUTER_API_KEY"
approval_policy = "never"

[profiles.k2]
model_provider = "openrouter"
model = "moonshotai/kimi-k2"

# MCP (Model Context Protocol) servers
[mcp_servers.context7]
command = "npx"
args = ["-y", "@upstash/context7-mcp"]

[mcp_servers.sequential-thinking]
command = "npx"
args = ["-y", "@modelcontextprotocol/server-sequential-thinking"]
